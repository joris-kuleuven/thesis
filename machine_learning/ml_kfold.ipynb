{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix, matthews_corrcoef, f1_score, precision_score\n",
    "from numpy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_vars_dir = \"/Users/jorismachon/Documents/thesis/ML_data/vars\"\n",
    "data_in_path = \"/Users/jorismachon/Documents/thesis/tabulated_commits_v14_nov.json\"\n",
    "data_in_path = \"/Users/jorismachon/Documents/thesis/ML_data/subsets/allValid.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bool_cols_to_bin_cols(df):\n",
    "    bin_cols = [\"fix\", \"is_vulnerable\", \"neutral\", \"new_author\", \"oop_php_files_exist\", \"authorPresent\"]\n",
    "    # Change binaries to 0 and 1\n",
    "    for col in bin_cols:\n",
    "        df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_diff_col(df):\n",
    "    # TIMEZONE\n",
    "    df['author_info.created_at'].replace(-1, np.nan, inplace=True)\n",
    "    df['author_date'] = pd.to_datetime(df['author_date'], unit='ms')\n",
    "    df['author_timezone'] = pd.to_timedelta(df['author_timezone'], unit='s')\n",
    "    # Combine author_date and author_timezone to create a new column representing the actual date and time\n",
    "    df['commit_time'] = df['author_date'] + df['author_timezone']    \n",
    "\n",
    "    # columns_to_drop = df.filter(regex='^BoW_').columns\n",
    "    # df_final = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    df['author_info.created_at'] = pd.to_datetime(df['author_info.created_at'], errors='coerce', utc=True)\n",
    "    df['commit_time'] = pd.to_datetime(df['commit_time'], errors='coerce', utc=True)\n",
    "\n",
    "    df.loc[df['author_x'] != None, 'time_difference'] = (df.loc[df['author_x'] != None, 'commit_time'] - df.loc[df['author_x'] != None, 'author_info.created_at']).dt.days\n",
    "    df['time_difference'].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def balancing(df, desired_ratio):    \n",
    "#     y = df['is_vulnerable']\n",
    "#     X = df.drop(columns=['is_vulnerable'])\n",
    "#     rus = RandomUnderSampler(sampling_strategy=desired_ratio, random_state=42)\n",
    "#     X_balanced, y_balanced = rus.fit_resample(X, y)\n",
    "#     return X_balanced, y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_smote(X_train, y_train, desired_ratio):\n",
    "    smote = SMOTE(sampling_strategy=desired_ratio, random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    return X_train_resampled, y_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vif(X):\n",
    "    # Calculating VIF\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df_in):\n",
    "    nr_of_columns_init = df_in.shape[1]\n",
    "    vif1 = calc_vif(df_in)\n",
    "    a=vif1.VIF.max()\n",
    "    while a > 5:\n",
    "        maximum_a = vif1.loc[vif1['VIF'] == vif1['VIF'].max()]\n",
    "        vif1 = vif1.loc[vif1['variables'] != maximum_a.iloc[0,0]]\n",
    "        vif1 = calc_vif(df_in[vif1.variables.tolist()])\n",
    "        a = vif1.VIF.max()\n",
    "        # print(a)\n",
    "\n",
    "    X = df_in[vif1.variables.tolist()]\n",
    "    nr_of_columns_final = X.shape[1]\n",
    "    print(\"Selected \", nr_of_columns_final, \" out of \", nr_of_columns_init, \" features.\")\n",
    "    # print(\"Selected features: \", X.columns)\n",
    "    print(\"Dropped features: \", [col for col in df_in.columns if col not in X.columns])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(source):\n",
    "    print(\"Pre-processing data...\")\n",
    "    \n",
    "    \n",
    "    # Check if the file ends with .csv or .json\n",
    "    if source.endswith('.csv'):\n",
    "        # Read CSV file\n",
    "        tc_df = pd.read_csv(source)\n",
    "    elif source.endswith('.json'):\n",
    "        # Read JSON file\n",
    "        tc_df = pd.read_json(source)\n",
    "    else:\n",
    "        # If the file extension is neither .csv nor .json, raise an error\n",
    "        raise ValueError(\"Unsupported file format. Please provide a CSV or JSON file.\")\n",
    "    print(\"Non-numerical processing\")\n",
    "    # tc_df.fillna(-1, inplace=True) #Replace all null values with -1\n",
    "    \n",
    "    num_rows_with_null = tc_df.isnull().any(axis=1).sum() # Count the number of rows with at least one null value\n",
    "    num_nulls = tc_df.isnull().sum().sum() # Count the number of null values in the dataframe\n",
    "    # tc_df.fillna(-1, inplace=True) # Replace all null values with -1\n",
    "    numeric_cols = tc_df.select_dtypes(include=[np.number]).columns\n",
    "    tc_df[numeric_cols] = tc_df[numeric_cols].fillna(tc_df[numeric_cols].mean())\n",
    "    print(f\"Replaced {num_nulls} null values in \", num_rows_with_null, \" rows with mean.\")\n",
    "\n",
    "    \n",
    "    # bool_cols_to_bin_cols(tc_df) #boolean columns to binary\n",
    "    \n",
    "    # create_time_diff_col(tc_df) #create a time difference col that calculates the time diff between author creation and commit time\n",
    "    \n",
    "    # tc_df = tc_df.drop(columns=[\"appname\", #drop unused columns\n",
    "    #                                                   \"author_info.username\", \n",
    "    #                                                   \"author_x\", \"author_y\", \n",
    "    #                                                   \"commit_sha\", \"repo\", \n",
    "    #                                                   \"author_info.created_at\", \n",
    "    #                                                   \"author_date\", \n",
    "    #                                                   \"author_timezone\",\n",
    "    #                                                   \"neutral\"])\n",
    "    # Get columns that start with 'BoW'\n",
    "    # cols_to_drop = tc_df.filter(regex='^BoW').columns\n",
    "    # tc_df = tc_df.drop(columns=cols_to_drop)\n",
    "\n",
    "    y = tc_df['is_vulnerable']\n",
    "    X = tc_df.drop(columns=['is_vulnerable'])\n",
    "    X = X.drop(columns=['appname'])\n",
    "\n",
    "    print(\"Balancing...\")\n",
    "    # X, y = balancing(tc_df, 1)\n",
    "    print(\"Feature selection with VIF...\")\n",
    "    # colX = [c for c in feature_selection(X.drop(columns=['commit_time']))]\n",
    "    colX = [c for c in feature_selection(X)]\n",
    "\n",
    "    X = X[colX]\n",
    "    print(\"Pre-processing done!\\n\")\n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_variables(file_name, variables):\n",
    "    file_path = os.path.join(ml_vars_dir, file_name)\n",
    "    with open(file_path, 'wb') as handle:\n",
    "        pickle.dump(variables, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cv_save_results(clf_name, cv, X_final, y_final, save_file_name, Xy_are_np=False):\n",
    "    if not Xy_are_np:    \n",
    "        X_final_np = X_final.values\n",
    "        y_final_np = y_final.values\n",
    "    else:\n",
    "        X_final_np = X_final\n",
    "        y_final_np = y_final\n",
    "    if clf_name == \"AdaBoostClassifier\":\n",
    "        clf = AdaBoostClassifier(n_estimators=1900, learning_rate=0.1, random_state=0)\n",
    "    else:\n",
    "        raise Exception(\"Clf not set for clf name\", clf_name)\n",
    "    splits_indices = cv.split(X_final_np, y_final_np)\n",
    "\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "\n",
    "    N, P = X_final_np.shape\n",
    "\n",
    "    # Aggregate the importances over folds here:\n",
    "    importances_random = np.zeros(P)\n",
    "\n",
    "    # Loop over crossvalidation folds:\n",
    "    scores = []  # Collect accuracies here\n",
    "\n",
    "    TP = []\n",
    "    FP = []\n",
    "    TN = []\n",
    "    FN = []\n",
    "    tnList = []\n",
    "    fpList = []\n",
    "    fnList = []\n",
    "    tpList = []\n",
    "    precisionList = []\n",
    "    f1List = []\n",
    "    mccList = []\n",
    "\n",
    "    i = 1\n",
    "    count = 0\n",
    "    # for train, test in cv.split(X, y):\n",
    "    train_splits = []\n",
    "    test_splits = []\n",
    "    train_anomaly_percentage = []\n",
    "    test_anomaly_percentage = []\n",
    "    train_anomaly_absolute = []\n",
    "    test_anomaly_absolute = []\n",
    "    counterfold = 1\n",
    "    for train, test in splits_indices:\n",
    "        print(\"Fold-repetition\", counterfold)\n",
    "        counterfold+=1\n",
    "        train_splits.append(train)\n",
    "        test_splits.append(test)\n",
    "        count += 1\n",
    "\n",
    "        X_train = X_final_np[train]\n",
    "        y_train = y_final_np[train]\n",
    "        X_test = X_final_np[test]\n",
    "        y_test = y_final_np[test]\n",
    "\n",
    "        X_train, y_train = apply_smote(X_train, y_train, 1)\n",
    "\n",
    "        a, b = np.unique(y_train, return_counts=True)[1]\n",
    "        train_anomaly_percentage.append(b / (a + b))\n",
    "        train_anomaly_absolute.append(b)\n",
    "        c, d = np.unique(y_test, return_counts=True)[1]\n",
    "        test_anomaly_percentage.append(d / (c + d))\n",
    "        test_anomaly_absolute.append(d)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Predict for validation data_raw:\n",
    "\n",
    "        \n",
    "        probas_ = clf.predict_proba(X_test)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # Compute ROC curve and area under the curve\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1], pos_label=1)\n",
    "\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "\n",
    "        # calculate confusion matrix, precision, f1 and Matthews Correlation Coefficient\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        TN.append(tn)\n",
    "        TP.append(tp)\n",
    "        FN.append(fn)\n",
    "        FP.append(fp)\n",
    "\n",
    "        tnList.append(tn / (tn + fp))\n",
    "        tpList.append(tp / (fn + tp))\n",
    "        fpList.append(fp / (tn + fp))\n",
    "        fnList.append(fn / (fn + tp))\n",
    "\n",
    "        precisionList.append(precision)\n",
    "        f1List.append(f1)\n",
    "        mccList.append(mcc)\n",
    "\n",
    "        i += 1\n",
    "        \n",
    "    tnList = 100 * np.array(tnList)\n",
    "    tpList = 100 * np.array(tpList)\n",
    "    fnList = 100 * np.array(fnList)\n",
    "    fpList = 100 * np.array(fpList)\n",
    "    precisionList = 100 * np.array(precisionList)\n",
    "    f1List = 100 * np.array(f1List)\n",
    "    mccList = 100 * np.array(mccList)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    # mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    mean_auc = np.mean(aucs)\n",
    "    std_auc = np.std(aucs)\n",
    "    auc_meanpercent = 100 * mean_auc\n",
    "    auc_stdpercent = 100 * std_auc\n",
    "\n",
    "    variables_to_save = {\n",
    "        'tprs': tprs,\n",
    "        'aucs': aucs,\n",
    "        'N': N,\n",
    "        'P': P,\n",
    "        'importances_random': importances_random,\n",
    "        'scores': scores,\n",
    "        'TP': TP,\n",
    "        'FP': FP,\n",
    "        'TN': TN,\n",
    "        'FN': FN,\n",
    "        'tnList': tnList,\n",
    "        'fpList': fpList,\n",
    "        'fnList': fnList,\n",
    "        'tpList': tpList,\n",
    "        'precisionList': precisionList,\n",
    "        'f1List': f1List,\n",
    "        'mccList': mccList,\n",
    "        'train_splits': train_splits,\n",
    "        'test_splits': test_splits,\n",
    "        'train_anomaly_percentage': train_anomaly_percentage,\n",
    "        'test_anomaly_percentage': test_anomaly_percentage,\n",
    "        'train_anomaly_absolute': train_anomaly_absolute,\n",
    "        'test_anomaly_absolute': test_anomaly_absolute,\n",
    "        'auc_meanpercent': auc_meanpercent,\n",
    "        'auc_stdpercent' : auc_stdpercent\n",
    "    }\n",
    "    save_variables(save_file_name, variables_to_save)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_variables(file_name):\n",
    "    file_path = os.path.join(ml_vars_dir, file_name)\n",
    "    with open(file_path, 'rb') as handle:\n",
    "        loaded_variables = pickle.load(handle)    \n",
    "    return loaded_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_show_metrics(file_name):\n",
    "    print(\"Showing metrics for file\", file_name)\n",
    "    # Load variables from the file\n",
    "    loaded_variables = load_variables(file_name)\n",
    "    # Return each variable separately\n",
    "    tprs = loaded_variables['tprs']\n",
    "    aucs = loaded_variables['aucs']\n",
    "    N = loaded_variables['N']\n",
    "    P = loaded_variables['P']\n",
    "    importances_random = loaded_variables['importances_random']\n",
    "    scores = loaded_variables['scores']\n",
    "    TP = loaded_variables['TP']\n",
    "    FP = loaded_variables['FP']\n",
    "    TN = loaded_variables['TN']\n",
    "    FN = loaded_variables['FN']\n",
    "    tnList = loaded_variables['tnList']\n",
    "    fpList = loaded_variables['fpList']\n",
    "    fnList = loaded_variables['fnList']\n",
    "    tpList = loaded_variables['tpList']\n",
    "    precisionList = loaded_variables['precisionList']\n",
    "    f1List = loaded_variables['f1List']\n",
    "    mccList = loaded_variables['mccList']\n",
    "    train_splits = loaded_variables['train_splits']\n",
    "    test_splits = loaded_variables['test_splits']\n",
    "    train_anomaly_percentage = loaded_variables['train_anomaly_percentage']\n",
    "    test_anomaly_percentage = loaded_variables['test_anomaly_percentage']\n",
    "    train_anomaly_absolute = loaded_variables['train_anomaly_absolute']\n",
    "    test_anomaly_absolute = loaded_variables['test_anomaly_absolute']\n",
    "    \n",
    "    mean_auc = np.mean(aucs)\n",
    "    std_auc = np.std(aucs)\n",
    "    auc_meanpercent = 100 * mean_auc\n",
    "    auc_stdpercent = 100 * std_auc\n",
    "    \n",
    "    \"\"\"Show metrics\"\"\"\n",
    "    \n",
    "    plt.clf()  # Clear the current figure\n",
    "    \n",
    "    print(\"TN: %.02f %% ± %.02f %% - FN: %.02f %% ± %.02f %%\" % (np.mean(tnList),\n",
    "                                                                    np.std(tnList),\n",
    "                                                                    np.mean(fnList),\n",
    "                                                                    np.std(fnList)))\n",
    "    print(\"FP: %.02f %% ± %.02f %% - TP: %.02f %% ± %.02f %%\" % (np.mean(fpList),\n",
    "                                                                    np.std(fpList),\n",
    "                                                                    np.mean(tpList),\n",
    "                                                                    np.std(tpList)))\n",
    "\n",
    "    print(\n",
    "        \"Precision: %.02f %% ± %.02f %% - F1: %.02f %% ± %.02f %% - MCC: %.02f %% ± %.02f %%\" % (np.mean(precisionList),\n",
    "                                                                                                    np.std(precisionList),\n",
    "                                                                                                    np.mean(f1List),\n",
    "                                                                                                    np.std(f1List),\n",
    "                                                                                                    np.mean(mccList),\n",
    "                                                                                                    np.std(mccList)))\n",
    "\n",
    "    print(\"AUC: %.02f %% ± %.02f %%\" % (auc_meanpercent, auc_stdpercent))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_plot_metrics(file_name):\n",
    "    print(\"Showing metrics for file\", file_name)\n",
    "    # Load variables from the file\n",
    "    loaded_variables = load_variables(file_name)\n",
    "    f1List = loaded_variables['f1List']\n",
    "    tnList = loaded_variables['tnList']\n",
    "    fpList = loaded_variables['fpList']\n",
    "    fnList = loaded_variables['fnList']\n",
    "    tpList = loaded_variables['tpList']\n",
    "\n",
    "    # Create 2x2 grid of boxplots\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    # Boxplots\n",
    "    axs[0, 0].boxplot(tnList, vert=False, showfliers=False)\n",
    "    axs[0, 0].set_title('TN List')\n",
    "    axs[0, 1].boxplot(fpList, vert=False, showfliers=False)\n",
    "    axs[0, 1].set_title('FP List')\n",
    "    axs[1, 0].boxplot(fnList, vert=False, showfliers=False)\n",
    "    axs[1, 0].set_title('FN List')\n",
    "    axs[1, 1].boxplot(tpList, vert=False, showfliers=False)\n",
    "    axs[1, 1].set_title('TP List')\n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot boxplot of scores\n",
    "    plt.figure()\n",
    "    plt.boxplot(f1List)\n",
    "    plt.title('F1 Distribution')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ml_from_file(source, clf_name, save_file_name, folds=10, repeats=1):\n",
    "    X_final, y_final = data_preprocessing(source)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=folds, n_repeats=repeats, random_state=1)\n",
    "    train_cv_save_results(clf_name, cv, X_final, y_final, save_file_name)\n",
    "    load_show_metrics(save_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"abc_k5_r1_with_nulls_dataset13.pkl\"\n",
    "data_in_path = \"/Users/jorismachon/Documents/thesis/ML_data/subsets/13_subsets_with_nulls.csv\"\n",
    "train_ml_from_file(data_in_path, \"AdaBoostClassifier\", output_filename, folds=5, repeats=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_plot_metrics(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
