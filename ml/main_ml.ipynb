{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix, matthews_corrcoef, f1_score, precision_score\n",
    "from numpy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of directories\n",
    "\n",
    "this_dir = os.path.join(r\"C:\\Users\\yeska\\OneDrive - KU Leuven\\Documents\\master\", \"thesis\\ml\")\n",
    "data_dir = os.path.join(this_dir, \"data\")\n",
    "ml_vars_dir = os.path.join(data_dir, \"ml_vars\")\n",
    "tc_v13_path = os.path.join(data_dir, \"tabulated_commits_v13_nov.json\")\n",
    "tc_v14_path = os.path.join(data_dir, \"tabulated_commits_v14_nov.json\")\n",
    "jit_data = \"/home/deck/Documents/masterGT/mt/jit-vulnerability-prediction-master/scripts/ml_pipeline/data_for_analysis.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read this if this is your first time in this notebook\n",
    "\n",
    "This is not a neat notebook, might be a bit all over the place. Firstly, dont run the cells top down, its probably not gonna work. The first thing you want to run is the imports, and then the directories cell, you only need to change the \"this_dir\", change it to your own root directory!\n",
    "\n",
    "### Which cell to run?\n",
    "\n",
    "Go to section 3. Final function, it contains the cell the defines the main wrapper function. Run that cell defitions, go to the defintion of the children functions and run them as well, go to the defitions of the grandchildren functions and run them, and so on. The cells that defines these functions are a bit all over the place, so here is a quick breakdown of the ones that you need to run:\n",
    "\n",
    "- Section 1.2 contains def bool_cols_to_bin_cols(df) and def create_time_diff_col(df):\n",
    "- Section 1.3 contains def balancing(df, desired_ratio)\n",
    "- section 1.4 contains def feature_selection(X) and def calc_vif(X)\n",
    "- section 1.6 contains def data_preprocessing(source), this is the main wrapper function as explained in the beginning of section 1. Data pre-processing\n",
    "- section 2.1.1 contains def tune_hyperparameter(clf, name, cv), it's not used in the final function but you can run it if you want to test it\n",
    "- section 2.2.1 contains def train_cv_save_results(clf_name, cv, X_final, y_final, save_file_name, Xy_are_np=False) and def save_variables(file_name, variables)\n",
    "- section 2.3 contains def load_variables(file_name) and def load_show_metrics(file_name)\n",
    "- section 3 contains def train_ml_from_file(source, clf_name, save_file_name, folds=10, repeats=1), **this is the father of all the functions, this is the one that will be used to produce ml outputs from a source file**.\n",
    "\n",
    "### File namings for the results\n",
    "\n",
    "The final function train_ml_from_file(...) receives save_file_name, this is **only** the file_name! not the full path, also make sure that you add the extendion .pkl . The path is already set in the function. Also, please name it as {classifier_name}_k{number of folds}_r{number of repetitions}_{extra settings that you think are important}.pkl . For example, abc_k5_r5_v1.pkl means it uses ada boost classifier (and hence abc), 5 folds, 5 repertions, and version 1 (open up possibilities of other versions if necessary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data pre-processing\n",
    "\n",
    "1. Deal with null values\n",
    "2. Non-numerical values\n",
    "3. X and Y, plus balancing\n",
    "4. Feature selection with VIF\n",
    "5. Train, test split based on date\n",
    "6. **Main function for pre-processing**, this is the most important part if you want to run things (almost) right away. go to this section and run the cell that defines data_preprocessing(...). From that cell, ensure that you run the cells that defines the functions used in data_preprocessing(...), you can simply ctrl+leftclick the function (in vscode) to go the right function definition cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick data flattening\n",
    "\n",
    "tabulated_commits_v13_nov.json has a dictionary in each entry, needed to be flattened. Result is tabulated_commits_v14_nov.json.These cells do not need to be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(tc_v13_path, 'r') as f:\n",
    "    tc_v13 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(json_data, parent_key='', sep='_'):\n",
    "    \"\"\"\n",
    "    Flatten nested JSON structure\n",
    "    \"\"\"\n",
    "    items = {}\n",
    "    for k, v in json_data.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.update(flatten_json(v, new_key, sep=sep))\n",
    "        else:\n",
    "            items[new_key] = v\n",
    "    return items\n",
    "\n",
    "flattened_data = [flatten_json(item) for item in tc_v13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tc_v14_path, 'w') as f:\n",
    "    json.dump(flattened_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Null values dealing (and init df)\n",
    "Early pandas stuff, just to get to know the data a bit. There's also a line that replaces the null values with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tc_v14_df = pd.read_json(tc_v14_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_sha</th>\n",
       "      <th>is_vulnerable</th>\n",
       "      <th>neutral</th>\n",
       "      <th>author_x</th>\n",
       "      <th>author_info_username</th>\n",
       "      <th>author_info_public_repos</th>\n",
       "      <th>author_info_followers</th>\n",
       "      <th>author_info_following</th>\n",
       "      <th>author_info_public_gists</th>\n",
       "      <th>author_info_created_at</th>\n",
       "      <th>...</th>\n",
       "      <th>average_loc</th>\n",
       "      <th>average_ncloc</th>\n",
       "      <th>average_dit</th>\n",
       "      <th>average_nocc</th>\n",
       "      <th>average_cbo</th>\n",
       "      <th>average_wmc</th>\n",
       "      <th>average_ccn</th>\n",
       "      <th>average_hv</th>\n",
       "      <th>oop_php_files_exist</th>\n",
       "      <th>author_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>349162ea139556b2d25e09e155cec84e21cc9227</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ssddanbrown</td>\n",
       "      <td>ssddanbrown</td>\n",
       "      <td>74.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2014-08-03 13:20:04+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>192.5</td>\n",
       "      <td>162.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.25</td>\n",
       "      <td>1.682692</td>\n",
       "      <td>358.479178</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d41452f39c90deaca98b4fe0e8c87f7d7aa395b8</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ssddanbrown</td>\n",
       "      <td>ssddanbrown</td>\n",
       "      <td>74.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2014-08-03 13:20:04+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e639600ba5909941db97fdd3a4df4220d80f4c7a</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ssddanbrown</td>\n",
       "      <td>ssddanbrown</td>\n",
       "      <td>74.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2014-08-03 13:20:04+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eaa1765c7a68cd671bcb37a666203210bf05d217</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ssddanbrown</td>\n",
       "      <td>ssddanbrown</td>\n",
       "      <td>74.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2014-08-03 13:20:04+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bbd1384acbe7e52c21f89af69f2dc391c95dbf54</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>PercussiveElbow</td>\n",
       "      <td>PercussiveElbow</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2014-12-02 20:42:15+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>374.5</td>\n",
       "      <td>342.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>36.00</td>\n",
       "      <td>2.258242</td>\n",
       "      <td>333.389436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 commit_sha  is_vulnerable  neutral  \\\n",
       "0  349162ea139556b2d25e09e155cec84e21cc9227          False    False   \n",
       "1  d41452f39c90deaca98b4fe0e8c87f7d7aa395b8           True    False   \n",
       "2  e639600ba5909941db97fdd3a4df4220d80f4c7a           True    False   \n",
       "3  eaa1765c7a68cd671bcb37a666203210bf05d217           True    False   \n",
       "4  bbd1384acbe7e52c21f89af69f2dc391c95dbf54          False    False   \n",
       "\n",
       "          author_x author_info_username  author_info_public_repos  \\\n",
       "0      ssddanbrown          ssddanbrown                      74.0   \n",
       "1      ssddanbrown          ssddanbrown                      74.0   \n",
       "2      ssddanbrown          ssddanbrown                      74.0   \n",
       "3      ssddanbrown          ssddanbrown                      74.0   \n",
       "4  PercussiveElbow      PercussiveElbow                      28.0   \n",
       "\n",
       "   author_info_followers  author_info_following  author_info_public_gists  \\\n",
       "0                  372.0                   20.0                      44.0   \n",
       "1                  372.0                   20.0                      44.0   \n",
       "2                  372.0                   20.0                      44.0   \n",
       "3                  372.0                   20.0                      44.0   \n",
       "4                   26.0                   28.0                       8.0   \n",
       "\n",
       "     author_info_created_at  ... average_loc  average_ncloc  average_dit  \\\n",
       "0 2014-08-03 13:20:04+00:00  ...       192.5         162.25          2.0   \n",
       "1 2014-08-03 13:20:04+00:00  ...         NaN            NaN          NaN   \n",
       "2 2014-08-03 13:20:04+00:00  ...         NaN            NaN          NaN   \n",
       "3 2014-08-03 13:20:04+00:00  ...         NaN            NaN          NaN   \n",
       "4 2014-12-02 20:42:15+00:00  ...       374.5         342.50          1.0   \n",
       "\n",
       "   average_nocc  average_cbo  average_wmc  average_ccn  average_hv  \\\n",
       "0           0.0          9.0        14.25     1.682692  358.479178   \n",
       "1           NaN          NaN          NaN          NaN         NaN   \n",
       "2           NaN          NaN          NaN          NaN         NaN   \n",
       "3           NaN          NaN          NaN          NaN         NaN   \n",
       "4           0.0          3.5        36.00     2.258242  333.389436   \n",
       "\n",
       "   oop_php_files_exist  author_info  \n",
       "0                  1.0          NaN  \n",
       "1                  NaN          NaN  \n",
       "2                  NaN          NaN  \n",
       "3                  NaN          NaN  \n",
       "4                  1.0          NaN  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc_v14_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data is 4096\n",
      "No author count 668\n",
      "Yes author count 3428\n",
      "php files not exist (or not extracted) count 2219\n",
      "php files exist count 1877\n"
     ]
    }
   ],
   "source": [
    "# There are actually quite a lot of null values\n",
    "\n",
    "null_author_x_count = tc_v14_df['author_x'].isnull().sum()\n",
    "not_null_author_x_count = tc_v14_df['author_x'].notnull().sum()\n",
    "\n",
    "php_files_not_exist = tc_v14_df['oop_php_files_exist'].isnull().sum() + len(tc_v14_df[tc_v14_df[\"oop_php_files_exist\"]==0])\n",
    "php_files_exist = len(tc_v14_df[tc_v14_df[\"oop_php_files_exist\"]==1])\n",
    "\n",
    "print(\"total data is\", len(tc_v14_df))\n",
    "print(\"No author count\", null_author_x_count)\n",
    "print(\"Yes author count\", not_null_author_x_count)\n",
    "print(\"php files not exist (or not extracted) count\", php_files_not_exist)\n",
    "print(\"php files exist count\", php_files_exist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there's a lot of null values, we still don't know what to do with it, so we're going to replace it with -1 for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11691/1799309576.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-1' has dtype incompatible with datetime64[ns, UTC], please explicitly cast to a compatible dtype first.\n",
      "  tc_v14_df_filled.fillna(-1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "tc_v14_df_filled = tc_v14_df.copy()\n",
    "tc_v14_df_filled.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Non-numerical processings\n",
    "\n",
    "This is dropping some columns and changing some bool columns to binary. We also make the author creation date a time difference to the commit date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN FUNCTIONS\n",
    "def bool_cols_to_bin_cols(df):\n",
    "    bin_cols = [\"fix\", \"is_vulnerable\", \"neutral\", \"new_author\", \"oop_php_files_exist\"]\n",
    "    # Change binaries to 0 and 1\n",
    "    for col in bin_cols:\n",
    "        df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nonnumeric_cols(df):\n",
    "    # Identify numeric columns\n",
    "    numeric_columns = df.select_dtypes(include='number').columns\n",
    "\n",
    "    # List out non-numeric columns\n",
    "    non_numeric_columns = df.columns.difference(numeric_columns)\n",
    "\n",
    "    # Print non-numeric columns\n",
    "    print(\"Non-numeric columns:\")\n",
    "    for column in non_numeric_columns:\n",
    "        print(column)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_cols = [\"fix\", \"is_vulnerable\", \"neutral\", \"new_author\", \"oop_php_files_exist\"]\n",
    "# Change binaries to 0 and 1\n",
    "for col in bin_cols:\n",
    "    tc_v14_df_filled[col] = tc_v14_df_filled[col].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the function run below is to check if there's any nonnumeric cols left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns:\n",
      "appname\n",
      "author_info_created_at\n",
      "author_info_username\n",
      "author_x\n",
      "author_y\n",
      "commit_sha\n",
      "repo\n"
     ]
    }
   ],
   "source": [
    "print_nonnumeric_cols()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the better version for the timezone, use it for next iterations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length df:  4096\n",
      "number of unique commit SHAs:  4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11691/2970711136.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  tc_v14_df_filled['author_info_created_at'].replace(-1, np.nan, inplace=True)\n",
      "/tmp/ipykernel_11691/2970711136.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  tc_v14_df_filled['author_info_created_at'].replace(-1, np.nan, inplace=True)\n",
      "/tmp/ipykernel_11691/2970711136.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  tc_v14_df_filled['time_difference'].fillna(-1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TIMEZONE\n",
    "tc_v14_df_filled['author_info_created_at'].replace(-1, np.nan, inplace=True)\n",
    "tc_v14_df_filled['author_date'] = pd.to_datetime(tc_v14_df_filled['author_date'], unit='ms')\n",
    "tc_v14_df_filled['author_timezone'] = pd.to_timedelta(tc_v14_df_filled['author_timezone'], unit='s')\n",
    "# Combine author_date and author_timezone to create a new column representing the actual date and time\n",
    "tc_v14_df_filled['commit_time'] = tc_v14_df_filled['author_date'] + tc_v14_df_filled['author_timezone']\n",
    "\n",
    "print(\"length df: \", len(tc_v14_df_filled))\n",
    "print(\"number of unique commit SHAs: \", len(tc_v14_df_filled['commit_sha'].unique()))\n",
    "\n",
    "# columns_to_drop = df.filter(regex='^BoW_').columns\n",
    "# df_final = df.drop(columns=columns_to_drop)\n",
    "\n",
    "tc_v14_df_filled['author_info_created_at'] = pd.to_datetime(tc_v14_df_filled['author_info_created_at'], errors='coerce', utc=True)\n",
    "tc_v14_df_filled['commit_time'] = pd.to_datetime(tc_v14_df_filled['commit_time'], errors='coerce', utc=True)\n",
    "\n",
    "tc_v14_df_filled.loc[tc_v14_df_filled['author_x'] != None, 'time_difference'] = (tc_v14_df_filled.loc[tc_v14_df_filled['author_x'] != None, 'commit_time'] - tc_v14_df_filled.loc[tc_v14_df_filled['author_x'] != None, 'author_info_created_at']).dt.days\n",
    "tc_v14_df_filled['time_difference'].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_diff_col(df):\n",
    "    # TIMEZONE\n",
    "    df['author_info_created_at'].replace(-1, np.nan, inplace=True)\n",
    "    df['author_date'] = pd.to_datetime(df['author_date'], unit='ms')\n",
    "    df['author_timezone'] = pd.to_timedelta(df['author_timezone'], unit='s')\n",
    "    # Combine author_date and author_timezone to create a new column representing the actual date and time\n",
    "    df['commit_time'] = df['author_date'] + df['author_timezone']    \n",
    "\n",
    "    # columns_to_drop = df.filter(regex='^BoW_').columns\n",
    "    # df_final = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    df['author_info_created_at'] = pd.to_datetime(df['author_info_created_at'], errors='coerce', utc=True)\n",
    "    df['commit_time'] = pd.to_datetime(df['commit_time'], errors='coerce', utc=True)\n",
    "\n",
    "    df.loc[df['author_x'] != None, 'time_difference'] = (df.loc[df['author_x'] != None, 'commit_time'] - df.loc[df['author_x'] != None, 'author_info_created_at']).dt.days\n",
    "    df['time_difference'].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      is_vulnerable  neutral  author_info_public_repos  author_info_followers  \\\n",
      "0                 0        0                      74.0                  372.0   \n",
      "1                 1        0                      74.0                  372.0   \n",
      "2                 1        0                      74.0                  372.0   \n",
      "3                 1        0                      74.0                  372.0   \n",
      "4                 0        0                      28.0                   26.0   \n",
      "...             ...      ...                       ...                    ...   \n",
      "4091              0        0                      58.0                  244.0   \n",
      "4092              0        0                      58.0                  244.0   \n",
      "4093              0        0                      58.0                  244.0   \n",
      "4094              0        0                      10.0                  108.0   \n",
      "4095              0        0                      10.0                  108.0   \n",
      "\n",
      "      author_info_following  author_info_public_gists  days_after_creation  \\\n",
      "0                      20.0                      44.0                 1890   \n",
      "1                      20.0                      44.0                 1771   \n",
      "2                      20.0                      44.0                  441   \n",
      "3                      20.0                      44.0                  -48   \n",
      "4                      28.0                       8.0                 1885   \n",
      "...                     ...                       ...                  ...   \n",
      "4091                   42.0                      13.0                 3597   \n",
      "4092                   42.0                      13.0                 3597   \n",
      "4093                   42.0                      13.0                 3597   \n",
      "4094                   10.0                      30.0                 3791   \n",
      "4095                   10.0                      30.0                 3791   \n",
      "\n",
      "      past_contributions  ratio_past_contributions  new_author  ...  \\\n",
      "0                   1681                  0.728652           0  ...   \n",
      "1                   1602                  0.730839           0  ...   \n",
      "2                    391                  0.955990           0  ...   \n",
      "3                      1                  1.000000           0  ...   \n",
      "4                      1                  0.000434           0  ...   \n",
      "...                  ...                       ...         ...  ...   \n",
      "4091                1622                  0.208752           0  ...   \n",
      "4092                1621                  0.208650           0  ...   \n",
      "4093                1620                  0.208548           0  ...   \n",
      "4094                1536                  0.180324           0  ...   \n",
      "4095                1537                  0.180420           0  ...   \n",
      "\n",
      "      average_dit  average_nocc  average_cbo  average_wmc  average_ccn  \\\n",
      "0             2.0           0.0          9.0        14.25     1.682692   \n",
      "1            -1.0          -1.0         -1.0        -1.00    -1.000000   \n",
      "2            -1.0          -1.0         -1.0        -1.00    -1.000000   \n",
      "3            -1.0          -1.0         -1.0        -1.00    -1.000000   \n",
      "4             1.0           0.0          3.5        36.00     2.258242   \n",
      "...           ...           ...          ...          ...          ...   \n",
      "4091          2.0           0.0         14.0        61.50     1.844415   \n",
      "4092         -1.0          -1.0         -1.0        -1.00    -1.000000   \n",
      "4093          2.0           0.0          6.0        13.50     1.928571   \n",
      "4094          2.0           0.0         23.5        60.00     1.711250   \n",
      "4095          2.0           0.0          5.0         8.00     1.375000   \n",
      "\n",
      "      average_hv  oop_php_files_exist  author_info               commit_time  \\\n",
      "0     358.479178                    1         -1.0 2020-10-31 15:01:52+00:00   \n",
      "1      -1.000000                   -1         -1.0 2020-07-04 14:53:02+00:00   \n",
      "2      -1.000000                   -1         -1.0 2016-11-12 14:12:26+00:00   \n",
      "3      -1.000000                   -1         -1.0 2015-07-12 18:01:42+00:00   \n",
      "4     333.389436                    1         -1.0 2020-10-27 01:34:51+00:00   \n",
      "...          ...                  ...          ...                       ...   \n",
      "4091  451.172875                    1         -1.0 2023-02-07 19:52:51+00:00   \n",
      "4092   -1.000000                    0         -1.0 2023-02-07 19:43:04+00:00   \n",
      "4093  247.811228                    1         -1.0 2023-02-07 19:42:46+00:00   \n",
      "4094  420.603476                    1         -1.0 2023-08-21 07:08:24+00:00   \n",
      "4095  294.162795                    1         -1.0 2023-08-21 07:08:47+00:00   \n",
      "\n",
      "      time_difference  \n",
      "0              2281.0  \n",
      "1              2162.0  \n",
      "2               832.0  \n",
      "3               343.0  \n",
      "4              2155.0  \n",
      "...               ...  \n",
      "4091           5081.0  \n",
      "4092           5081.0  \n",
      "4093           5081.0  \n",
      "4094           5101.0  \n",
      "4095           5101.0  \n",
      "\n",
      "[4096 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "tc_v14_df_filled = tc_v14_df_filled.drop(columns=[\"appname\", \"author_info_username\", \"author_x\", \"author_y\", \"commit_sha\", \"repo\", \"author_info_created_at\", \"author_date\", \"author_timezone\"])\n",
    "print(tc_v14_df_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns:\n",
      "commit_time\n"
     ]
    }
   ],
   "source": [
    "print_nonnumeric_cols()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "commit time is kept because initially we want to split the data by date, but since we're using repeated fold cross-validation, it's gonna be kinda complicated to do that. This commit_time feature will be removed later on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 X and Y, plus balancing\n",
    "\n",
    "balancing here is undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 46)\n",
      "(4096,)\n"
     ]
    }
   ],
   "source": [
    "y = tc_v14_df_filled['is_vulnerable']\n",
    "X = tc_v14_df_filled.drop(columns=['is_vulnerable'])\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#undersampling\n",
    "desired_ratio = 1 \n",
    "rus = RandomUnderSampler(sampling_strategy=desired_ratio, random_state=42)\n",
    "X_balanced, y_balanced = rus.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_resampled shape: (1838, 46)\n",
      "y_resampled shape: (1838,)\n",
      "vuln count 919\n",
      "non vuln count 919\n"
     ]
    }
   ],
   "source": [
    "print(\"X_resampled shape:\", X_balanced.shape)\n",
    "print(\"y_resampled shape:\", y_balanced.shape)\n",
    "\n",
    "print(\"vuln count\", len(y_balanced[y_balanced==1]))\n",
    "print(\"non vuln count\", len(y_balanced[y_balanced==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing(df, desired_ratio):    \n",
    "    y = df['is_vulnerable']\n",
    "    X = df.drop(columns=['is_vulnerable'])\n",
    "    rus = RandomUnderSampler(sampling_strategy=desired_ratio, random_state=42)\n",
    "    X_balanced, y_balanced = rus.fit_resample(X, y)\n",
    "    return X_balanced, y_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Feature selection with VIF\n",
    "\n",
    "VIF removes features that have collinearity, used in palomba jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vif(X):\n",
    "\n",
    "    # Calculating VIF\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return(vif)\n",
    "\n",
    "def feature_selection(X):\n",
    "    vif1 = calc_vif(X)\n",
    "    a=vif1.VIF.max()\n",
    "    while a > 5:\n",
    "        maximum_a = vif1.loc[vif1['VIF'] == vif1['VIF'].max()]\n",
    "        vif1 = vif1.loc[vif1['variables'] != maximum_a.iloc[0,0]]\n",
    "        vif1 = calc_vif(X[vif1.variables.tolist()])\n",
    "        a = vif1.VIF.max()\n",
    "        # print(a)\n",
    "\n",
    "    X = X[vif1.variables.tolist()]\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n"
     ]
    }
   ],
   "source": [
    "colX = [c for c in feature_selection(X_balanced.drop(columns=['commit_time']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral', 'author_info_public_repos', 'author_info_followers', 'author_info_following', 'author_info_public_gists', 'days_after_creation', 'past_contributions', 'ratio_past_contributions', 'new_author', 'past_contributions_30_days', 'dmm_unit_interf', 'fix', 'past_authors', 'sum_added_lines', 'med_added_lines', 'sum_deleted_lines', 'mean_deleted_lines', 'med_deleted_lines', 'med_hunks', 'med_previous_changes', 'sum_days_since_creation', 'med_days_since_creation', 'nr_of_blacklisted', 'php_metrics_extracted', 'average_dit', 'average_cbo', 'average_wmc', 'average_hv']\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(colX)\n",
    "print(len(colX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1838, 29)\n"
     ]
    }
   ],
   "source": [
    "colX.append('commit_time')\n",
    "X_vif = X_balanced[colX]\n",
    "print(X_vif.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Train test split with date\n",
    "\n",
    "this is ended up not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_based_on_time(X, y, ratio):\n",
    "    # Sort the DataFrame by commit_time\n",
    "    data = pd.concat([X, y], axis=1)\n",
    "    data = data.sort_values(by='commit_time')\n",
    "\n",
    "    # Calculate the index for splitting\n",
    "    split_index = int(len(data) * ratio)\n",
    "\n",
    "    # Split the DataFrame into training and test sets based on the calculated index\n",
    "    train_data = data.iloc[:split_index]\n",
    "    test_data = data.iloc[split_index:]\n",
    "\n",
    "    # Separate X and y for training and test sets\n",
    "    X_train = train_data.drop(columns=['is_vulnerable'])  # Assuming 'commit_time' is not a feature\n",
    "    y_train = train_data['is_vulnerable']\n",
    "    X_test = test_data.drop(columns=['is_vulnerable'])    # Assuming 'commit_time' is not a feature\n",
    "    y_test = test_data['is_vulnerable']\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def train_val_test_split(X, y, ratio):\n",
    "    X_train, y_train, X_val_test, y_val_test = split_based_on_time(X, y, ratio)\n",
    "    X_val, y_val, X_test, y_test = split_based_on_time(X_val_test, y_val_test, 0.5)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1838, 30)\n",
      "(736, 30)\n",
      "(1102, 29) (1102,) (368, 29) (368,) (368, 29) (368,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(X_vif, y_balanced, 0.6)\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1102, 28) (1102,) (368, 28) (368,) (368, 28) (368,)\n"
     ]
    }
   ],
   "source": [
    "X_train.drop(columns=[\"commit_time\"], inplace=True)\n",
    "X_val.drop(columns=[\"commit_time\"], inplace=True)\n",
    "X_test.drop(columns=[\"commit_time\"], inplace=True)\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596\n",
      "122\n",
      "201\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train[y_train==1]))\n",
    "print(len(y_test[y_test==1]))\n",
    "print(len(y_val[y_val==1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Main pre-processing function\n",
    "\n",
    "this is the main function that is used in the final function for training machine learning. Its a wrapper for everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(source):\n",
    "    print(\"Pre-processing data...\")\n",
    "    \n",
    "    \n",
    "    # Check if the file ends with .csv or .json\n",
    "    if source.endswith('.csv'):\n",
    "        # Read CSV file\n",
    "        tc_df = pd.read_csv(source)\n",
    "    elif source.endswith('.json'):\n",
    "        # Read JSON file\n",
    "        tc_df = pd.read_json(source)\n",
    "    else:\n",
    "        # If the file extension is neither .csv nor .json, raise an error\n",
    "        raise ValueError(\"Unsupported file format. Please provide a CSV or JSON file.\")\n",
    "    print(\"Non-numerical processing\")\n",
    "    tc_df.fillna(-1, inplace=True) #Replace all null values with -1\n",
    "    \n",
    "    bool_cols_to_bin_cols(tc_df) #boolean columns to binary\n",
    "    \n",
    "    create_time_diff_col(tc_df) #create a time difference col that calculates the time diff between author creation and commit time\n",
    "    \n",
    "    tc_df = tc_df.drop(columns=[\"appname\", #drop unused columns\n",
    "                                                      \"author_info_username\", \n",
    "                                                      \"author_x\", \"author_y\", \n",
    "                                                      \"commit_sha\", \"repo\", \n",
    "                                                      \"author_info_created_at\", \n",
    "                                                      \"author_date\", \n",
    "                                                      \"author_timezone\"])\n",
    "    print(\"Balancing...\")\n",
    "    X, y = balancing(tc_df, 1)\n",
    "    print(\"Feature selection with VIF...\")\n",
    "    colX = [c for c in feature_selection(X.drop(columns=['commit_time']))]\n",
    "    X = X[colX]\n",
    "    print(\"Pre-processing done!\\n\")\n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing data...\n",
      "Non-numerical processing\n",
      "Balancing...\n",
      "Feature selection with VIF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11691/2783531626.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-1' has dtype incompatible with datetime64[ns, UTC], please explicitly cast to a compatible dtype first.\n",
      "  tc_df.fillna(-1, inplace=True) #Replace all null values with -1\n",
      "/tmp/ipykernel_11691/84237121.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['author_info_created_at'].replace(-1, np.nan, inplace=True)\n",
      "/tmp/ipykernel_11691/84237121.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['author_info_created_at'].replace(-1, np.nan, inplace=True)\n",
      "/tmp/ipykernel_11691/84237121.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['time_difference'].fillna(-1, inplace=True)\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test the function\n",
    "X_final_test, y_final_test = data_preprocessing(tc_v14_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1838, 28) (1838,)\n",
      "[ 0.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
      " -1.00000000e+00 -9.70000000e+01  3.90000000e+01  2.74647887e-01\n",
      "  0.00000000e+00  2.00000000e+00  9.28151453e-01  1.00000000e+00\n",
      "  3.00000000e+00  8.40120000e+04  2.50000000e+01  3.76810000e+04\n",
      "  6.68102837e+01  2.10000000e+01  1.00000000e+00  1.30000000e+01\n",
      "  5.03056000e+05  8.04000000e+02  1.66000000e+02 -1.00000000e+00\n",
      " -1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n",
      "[ 0.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
      " -1.00000000e+00 -9.70000000e+01  3.90000000e+01  2.74647887e-01\n",
      "  0.00000000e+00  2.00000000e+00  9.28151453e-01  1.00000000e+00\n",
      "  3.00000000e+00  8.40120000e+04  2.50000000e+01  3.76810000e+04\n",
      "  6.68102837e+01  2.10000000e+01  1.00000000e+00  1.30000000e+01\n",
      "  5.03056000e+05  8.04000000e+02  1.66000000e+02 -1.00000000e+00\n",
      " -1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(X_final_test.shape, y_final_test.shape)\n",
    "print(X_final_test.values[1427])\n",
    "print(X_final_np[1427])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter tuning, training, and show metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Hyperparameter tuning\n",
    "\n",
    "the column commit_time is dropped here (for no good reason, but its not a big deal lol). RandomSearchCV is used for the tuning as it is used in the Palomba paper. Again simply go to the main function for hyperparameter tuning and run it if you want a (semi) plug and play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = X_vif.drop(columns = [\"commit_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1838, 28) (1838,)\n"
     ]
    }
   ],
   "source": [
    "print(X_final.shape, y_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "{'n_estimators': 1900, 'learning_rate': 0.1}\n",
      "0.9439919554846978\n"
     ]
    }
   ],
   "source": [
    "#classifiers = [(AdaBoostClassifier(n_estimators=100, random_state=0), \"AdaBoostClassifier\")]\n",
    "abc = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "n_estimators = np.arange(100, 2000, step=100)\n",
    "learning_rate = [0.001, 0.01, 0.1, 0.2, 0.5]\n",
    "\n",
    "param_space = {\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"learning_rate\": learning_rate\n",
    "}\n",
    "random_search = RandomizedSearchCV(abc, param_space, n_iter = 10, cv = cv, scoring='f1', n_jobs=-1, random_state=0, verbose=1)\n",
    "\n",
    "search = random_search.fit(X_final, y_balanced)\n",
    "\n",
    "best_param = search.best_params_\n",
    "best_score = search.best_score_\n",
    "print(best_param)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1838, 28) (1838,)\n",
      "Xfinal is [[  1.          20.         114.         ...   8.         171.66666667\n",
      "  740.54285663]\n",
      " [  1.         302.         173.         ...  15.5         33.5\n",
      "  432.51233496]\n",
      " [  1.          34.         632.         ...   0.           0.\n",
      "    0.        ]\n",
      " ...\n",
      " [  0.           6.         345.         ...  -1.          -1.\n",
      "   -1.        ]\n",
      " [  0.          32.           2.         ...  -1.          -1.\n",
      "   -1.        ]\n",
      " [  0.           6.         345.         ...  -1.          -1.\n",
      "   -1.        ]]\n",
      "yfinal is [0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "X_final_np = X_final.values\n",
    "y_balanced_np = y_balanced.values\n",
    "print(X_final_np.shape, y_balanced_np.shape)\n",
    "print(\"Xfinal is\", X_final_np)\n",
    "print(\"yfinal is\", y_balanced_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Hyperparameter tuning: Wrapper function\n",
    "run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping function for hyperparam tuning\n",
    "def tune_hyperparameter(clf, name, cv):    \n",
    "    if name == \"AdaBoostClassifier\":\n",
    "        n_estimators = np.arange(100, 2000, step=100)\n",
    "        learning_rate = [0.001, 0.01, 0.1, 0.2, 0.5]\n",
    "\n",
    "        param_space = {\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"learning_rate\": learning_rate\n",
    "        }\n",
    "    else:\n",
    "        raise Exception(\"Hyper parameter tuning param space not set for classifier\", name)\n",
    "    \n",
    "    random_search = RandomizedSearchCV(clf, param_space, n_iter = 10, cv = cv, scoring='f1', n_jobs=-1, random_state=0, verbose=1)\n",
    "\n",
    "    search = random_search.fit(X_final, y_balanced)\n",
    "\n",
    "    best_param = search.best_params_\n",
    "    best_score = search.best_score_\n",
    "    print(\"the best parameters are\", best_param)\n",
    "    print(\"with (the best) score being\", best_score)\n",
    "    return best_param, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "the best parameters are {'n_estimators': 1900, 'learning_rate': 0.1}\n",
      "with (the best) score being 0.9439919554846978\n"
     ]
    }
   ],
   "source": [
    "# test the hyperparam tuning\n",
    "abc = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "best_param_test, best_score_test = tune_hyperparameter(abc, \"AdaBoostClassifier\", cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Training the model\n",
    "\n",
    "the first cell is the first script that was tested to run. The cells after are the wrapper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 of 10\n",
      "\n",
      "\n",
      "Fold 2 of 10\n",
      "\n",
      "\n",
      "Fold 3 of 10\n",
      "\n",
      "\n",
      "Fold 4 of 10\n",
      "\n",
      "\n",
      "Fold 5 of 10\n",
      "\n",
      "\n",
      "Fold 6 of 10\n",
      "\n",
      "\n",
      "Fold 7 of 10\n",
      "\n",
      "\n",
      "Fold 8 of 10\n",
      "\n",
      "\n",
      "Fold 9 of 10\n",
      "\n",
      "\n",
      "Fold 10 of 10\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abc_tuned = AdaBoostClassifier(n_estimators=1900, learning_rate=0.1, random_state=0)\n",
    "splits_indices = cv.split(X_final_np, y_balanced_np)\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "tprs = []\n",
    "aucs = []\n",
    "\n",
    "N, P = X_final_np.shape\n",
    "\n",
    "# Aggregate the importances over folds here:\n",
    "importances_random = np.zeros(P)\n",
    "\n",
    "# Loop over crossvalidation folds:\n",
    "scores = []  # Collect accuracies here\n",
    "\n",
    "TP = []\n",
    "FP = []\n",
    "TN = []\n",
    "FN = []\n",
    "tnList = []\n",
    "fpList = []\n",
    "fnList = []\n",
    "tpList = []\n",
    "precisionList = []\n",
    "f1List = []\n",
    "mccList = []\n",
    "\n",
    "i = 1\n",
    "count = 0\n",
    "# for train, test in cv.split(X, y):\n",
    "train_splits = []\n",
    "test_splits = []\n",
    "train_anomaly_percentage = []\n",
    "test_anomaly_percentage = []\n",
    "train_anomaly_absolute = []\n",
    "test_anomaly_absolute = []\n",
    "counterfold = 1\n",
    "for train, test in splits_indices:\n",
    "    print('Fold %s of 10' %counterfold)\n",
    "    counterfold+=1\n",
    "    train_splits.append(train)\n",
    "    test_splits.append(test)\n",
    "    count += 1\n",
    "\n",
    "    X_train = X_final_np[train]\n",
    "    y_train = y_balanced_np[train]\n",
    "    X_test = X_final_np[test]\n",
    "    y_test = y_balanced_np[test]\n",
    "\n",
    "    a, b = np.unique(y_train, return_counts=True)[1]\n",
    "    train_anomaly_percentage.append(b / (a + b))\n",
    "    train_anomaly_absolute.append(b)\n",
    "    c, d = np.unique(y_test, return_counts=True)[1]\n",
    "    test_anomaly_percentage.append(d / (c + d))\n",
    "    test_anomaly_absolute.append(d)\n",
    "\n",
    "    abc_tuned.fit(X_train, y_train)\n",
    "\n",
    "    # Predict for validation data_raw:\n",
    "\n",
    "    \n",
    "    probas_ = abc_tuned.predict_proba(X_test)\n",
    "    y_pred = abc_tuned.predict(X_test)\n",
    "\n",
    "    # Compute ROC curve and area under the curve\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1], pos_label=1)\n",
    "\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "\n",
    "    # calculate confusion matrix, precision, f1 and Matthews Correlation Coefficient\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    TN.append(tn)\n",
    "    TP.append(tp)\n",
    "    FN.append(fn)\n",
    "    FP.append(fp)\n",
    "\n",
    "    tnList.append(tn / (tn + fp))\n",
    "    tpList.append(tp / (fn + tp))\n",
    "    fpList.append(fp / (tn + fp))\n",
    "    fnList.append(fn / (fn + tp))\n",
    "\n",
    "    precisionList.append(precision)\n",
    "    f1List.append(f1)\n",
    "    mccList.append(mcc)\n",
    "\n",
    "    i += 1\n",
    "    print(\"\\n\")\n",
    "    \n",
    "print(\"confusion matrix\")\n",
    "tnList = 100 * np.array(tnList)\n",
    "tpList = 100 * np.array(tpList)\n",
    "fnList = 100 * np.array(fnList)\n",
    "fpList = 100 * np.array(fpList)\n",
    "precisionList = 100 * np.array(precisionList)\n",
    "f1List = 100 * np.array(f1List)\n",
    "mccList = 100 * np.array(mccList)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "# mean_auc = auc(mean_fpr, mean_tpr)\n",
    "mean_auc = np.mean(aucs)\n",
    "std_auc = np.std(aucs)\n",
    "auc_meanpercent = 100 * mean_auc\n",
    "auc_stdpercent = 100 * std_auc\n",
    "\n",
    "variables_to_save = {\n",
    "    'tprs': tprs,\n",
    "    'aucs': aucs,\n",
    "    'N': N,\n",
    "    'P': P,\n",
    "    'importances_random': importances_random,\n",
    "    'scores': scores,\n",
    "    'TP': TP,\n",
    "    'FP': FP,\n",
    "    'TN': TN,\n",
    "    'FN': FN,\n",
    "    'tnList': tnList,\n",
    "    'fpList': fpList,\n",
    "    'fnList': fnList,\n",
    "    'tpList': tpList,\n",
    "    'precisionList': precisionList,\n",
    "    'f1List': f1List,\n",
    "    'mccList': mccList,\n",
    "    'train_splits': train_splits,\n",
    "    'test_splits': test_splits,\n",
    "    'train_anomaly_percentage': train_anomaly_percentage,\n",
    "    'test_anomaly_percentage': test_anomaly_percentage,\n",
    "    'train_anomaly_absolute': train_anomaly_absolute,\n",
    "    'test_anomaly_absolute': test_anomaly_absolute\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Training the model: wrapper functions\n",
    "\n",
    "the main function is train_cv_save_results(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_variables(file_name, variables):\n",
    "    file_path = os.path.join(ml_vars_dir, file_name)\n",
    "    with open(file_path, 'wb') as handle:\n",
    "        pickle.dump(variables, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cv_save_results(clf_name, cv, X_final, y_final, save_file_name, Xy_are_np=False):\n",
    "    if not Xy_are_np:    \n",
    "        X_final_np = X_final.values\n",
    "        y_final_np = y_final.values\n",
    "    else:\n",
    "        X_final_np = X_final\n",
    "        y_final_np = y_final\n",
    "    if clf_name == \"AdaBoostClassifier\":\n",
    "        clf = AdaBoostClassifier(n_estimators=1900, learning_rate=0.1, random_state=0)\n",
    "    else:\n",
    "        raise Exception(\"Clf not set for clf name\", clf_name)\n",
    "    splits_indices = cv.split(X_final_np, y_final_np)\n",
    "\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "\n",
    "    N, P = X_final_np.shape\n",
    "\n",
    "    # Aggregate the importances over folds here:\n",
    "    importances_random = np.zeros(P)\n",
    "\n",
    "    # Loop over crossvalidation folds:\n",
    "    scores = []  # Collect accuracies here\n",
    "\n",
    "    TP = []\n",
    "    FP = []\n",
    "    TN = []\n",
    "    FN = []\n",
    "    tnList = []\n",
    "    fpList = []\n",
    "    fnList = []\n",
    "    tpList = []\n",
    "    precisionList = []\n",
    "    f1List = []\n",
    "    mccList = []\n",
    "\n",
    "    i = 1\n",
    "    count = 0\n",
    "    # for train, test in cv.split(X, y):\n",
    "    train_splits = []\n",
    "    test_splits = []\n",
    "    train_anomaly_percentage = []\n",
    "    test_anomaly_percentage = []\n",
    "    train_anomaly_absolute = []\n",
    "    test_anomaly_absolute = []\n",
    "    counterfold = 1\n",
    "    for train, test in splits_indices:\n",
    "        print(\"Fold-repetition\", counterfold)\n",
    "        counterfold+=1\n",
    "        train_splits.append(train)\n",
    "        test_splits.append(test)\n",
    "        count += 1\n",
    "\n",
    "        X_train = X_final_np[train]\n",
    "        y_train = y_final_np[train]\n",
    "        X_test = X_final_np[test]\n",
    "        y_test = y_final_np[test]\n",
    "\n",
    "        a, b = np.unique(y_train, return_counts=True)[1]\n",
    "        train_anomaly_percentage.append(b / (a + b))\n",
    "        train_anomaly_absolute.append(b)\n",
    "        c, d = np.unique(y_test, return_counts=True)[1]\n",
    "        test_anomaly_percentage.append(d / (c + d))\n",
    "        test_anomaly_absolute.append(d)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Predict for validation data_raw:\n",
    "\n",
    "        \n",
    "        probas_ = clf.predict_proba(X_test)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # Compute ROC curve and area under the curve\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1], pos_label=1)\n",
    "\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "\n",
    "        # calculate confusion matrix, precision, f1 and Matthews Correlation Coefficient\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        TN.append(tn)\n",
    "        TP.append(tp)\n",
    "        FN.append(fn)\n",
    "        FP.append(fp)\n",
    "\n",
    "        tnList.append(tn / (tn + fp))\n",
    "        tpList.append(tp / (fn + tp))\n",
    "        fpList.append(fp / (tn + fp))\n",
    "        fnList.append(fn / (fn + tp))\n",
    "\n",
    "        precisionList.append(precision)\n",
    "        f1List.append(f1)\n",
    "        mccList.append(mcc)\n",
    "\n",
    "        i += 1\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    tnList = 100 * np.array(tnList)\n",
    "    tpList = 100 * np.array(tpList)\n",
    "    fnList = 100 * np.array(fnList)\n",
    "    fpList = 100 * np.array(fpList)\n",
    "    precisionList = 100 * np.array(precisionList)\n",
    "    f1List = 100 * np.array(f1List)\n",
    "    mccList = 100 * np.array(mccList)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    # mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    mean_auc = np.mean(aucs)\n",
    "    std_auc = np.std(aucs)\n",
    "    auc_meanpercent = 100 * mean_auc\n",
    "    auc_stdpercent = 100 * std_auc\n",
    "\n",
    "    variables_to_save = {\n",
    "        'tprs': tprs,\n",
    "        'aucs': aucs,\n",
    "        'N': N,\n",
    "        'P': P,\n",
    "        'importances_random': importances_random,\n",
    "        'scores': scores,\n",
    "        'TP': TP,\n",
    "        'FP': FP,\n",
    "        'TN': TN,\n",
    "        'FN': FN,\n",
    "        'tnList': tnList,\n",
    "        'fpList': fpList,\n",
    "        'fnList': fnList,\n",
    "        'tpList': tpList,\n",
    "        'precisionList': precisionList,\n",
    "        'f1List': f1List,\n",
    "        'mccList': mccList,\n",
    "        'train_splits': train_splits,\n",
    "        'test_splits': test_splits,\n",
    "        'train_anomaly_percentage': train_anomaly_percentage,\n",
    "        'test_anomaly_percentage': test_anomaly_percentage,\n",
    "        'train_anomaly_absolute': train_anomaly_absolute,\n",
    "        'test_anomaly_absolute': test_anomaly_absolute,\n",
    "        'auc_meanpercent': auc_meanpercent,\n",
    "        'auc_stdpercent' : auc_stdpercent\n",
    "    }\n",
    "    save_variables(save_file_name, variables_to_save)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 of 10\n",
      "\n",
      "\n",
      "Fold 2 of 10\n",
      "\n",
      "\n",
      "Fold 3 of 10\n",
      "\n",
      "\n",
      "Fold 4 of 10\n",
      "\n",
      "\n",
      "Fold 5 of 10\n",
      "\n",
      "\n",
      "Fold 6 of 10\n",
      "\n",
      "\n",
      "Fold 7 of 10\n",
      "\n",
      "\n",
      "Fold 8 of 10\n",
      "\n",
      "\n",
      "Fold 9 of 10\n",
      "\n",
      "\n",
      "Fold 10 of 10\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test train wrapper function\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "train_cv_save_results(\"AdaBoostClassifier\", cv, X_final_test, y_final_test, \"abc_k10_r1_v2.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Load metrics and show\n",
    "\n",
    "The main function is load_show_metrics(...). Run that and also load_variables(...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_variables(file_name):\n",
    "    file_path = os.path.join(ml_vars_dir, file_name)\n",
    "    with open(file_path, 'rb') as handle:\n",
    "        loaded_variables = pickle.load(handle)    \n",
    "    return loaded_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_show_metrics(file_name):\n",
    "    print(\"Showing metrics for file\", file_name)\n",
    "    # Load variables from the file\n",
    "    loaded_variables = load_variables(file_name)\n",
    "    # Return each variable separately\n",
    "    tprs = loaded_variables['tprs']\n",
    "    aucs = loaded_variables['aucs']\n",
    "    N = loaded_variables['N']\n",
    "    P = loaded_variables['P']\n",
    "    importances_random = loaded_variables['importances_random']\n",
    "    scores = loaded_variables['scores']\n",
    "    TP = loaded_variables['TP']\n",
    "    FP = loaded_variables['FP']\n",
    "    TN = loaded_variables['TN']\n",
    "    FN = loaded_variables['FN']\n",
    "    tnList = loaded_variables['tnList']\n",
    "    fpList = loaded_variables['fpList']\n",
    "    fnList = loaded_variables['fnList']\n",
    "    tpList = loaded_variables['tpList']\n",
    "    precisionList = loaded_variables['precisionList']\n",
    "    f1List = loaded_variables['f1List']\n",
    "    mccList = loaded_variables['mccList']\n",
    "    train_splits = loaded_variables['train_splits']\n",
    "    test_splits = loaded_variables['test_splits']\n",
    "    train_anomaly_percentage = loaded_variables['train_anomaly_percentage']\n",
    "    test_anomaly_percentage = loaded_variables['test_anomaly_percentage']\n",
    "    train_anomaly_absolute = loaded_variables['train_anomaly_absolute']\n",
    "    test_anomaly_absolute = loaded_variables['test_anomaly_absolute']\n",
    "    \n",
    "    mean_auc = np.mean(aucs)\n",
    "    std_auc = np.std(aucs)\n",
    "    auc_meanpercent = 100 * mean_auc\n",
    "    auc_stdpercent = 100 * std_auc\n",
    "    \n",
    "    \"\"\"Show metrics\"\"\"\n",
    "    \n",
    "    plt.clf()  # Clear the current figure\n",
    "    \n",
    "    print(\"TN: %.02f %% Â± %.02f %% - FN: %.02f %% Â± %.02f %%\" % (np.mean(tnList),\n",
    "                                                                    np.std(tnList),\n",
    "                                                                    np.mean(fnList),\n",
    "                                                                    np.std(fnList)))\n",
    "    print(\"FP: %.02f %% Â± %.02f %% - TP: %.02f %% Â± %.02f %%\" % (np.mean(fpList),\n",
    "                                                                    np.std(fpList),\n",
    "                                                                    np.mean(tpList),\n",
    "                                                                    np.std(tpList)))\n",
    "\n",
    "    print(\n",
    "        \"Precision: %.02f %% Â± %.02f %% - F1: %.02f %% Â± %.02f %% - MCC: %.02f %% Â± %.02f %%\" % (np.mean(precisionList),\n",
    "                                                                                                    np.std(precisionList),\n",
    "                                                                                                    np.mean(f1List),\n",
    "                                                                                                    np.std(f1List),\n",
    "                                                                                                    np.mean(mccList),\n",
    "                                                                                                    np.std(mccList)))\n",
    "\n",
    "    print(\"AUC: %.02f %% Â± %.02f %%\" % (auc_meanpercent, auc_stdpercent))\n",
    "    # plt.figure(1)  # Create a new figure\n",
    "    # plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "    #             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "    #             lw=2, alpha=.8)\n",
    "\n",
    "    # std_tpr = np.std(tprs, axis=0)\n",
    "    # tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    # tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    # plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "    #                     label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    # xlim = [-0.05, 1.05]\n",
    "    # ylim = [-0.05, 1.05]\n",
    "    # plt.xlim(xlim)\n",
    "    # plt.ylim(ylim)\n",
    "    # plt.xlabel('False Positive Rate')\n",
    "    # plt.ylabel('True Positive Rate')\n",
    "    # plt.legend(loc=\"lower right\")\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing metrics for file abc_k10_r1_v1.pkl\n",
      "TN: 92.49 % Â± 2.82 % - FN: 3.91 % Â± 1.83 %\n",
      "FP: 7.51 % Â± 2.82 % - TP: 96.09 % Â± 1.83 %\n",
      "Precision: 92.84 % Â± 2.43 % - F1: 94.40 % Â± 1.23 % - MCC: 88.70 % Â± 2.54 %\n",
      "AUC: 98.48 % Â± 0.57 %\n",
      "Showing metrics for file abc_k5_r5_v1.pkl\n",
      "TN: 96.95 % Â± 1.19 % - FN: 0.65 % Â± 0.65 %\n",
      "FP: 3.05 % Â± 1.19 % - TP: 99.35 % Â± 0.65 %\n",
      "Precision: 97.04 % Â± 1.13 % - F1: 98.17 % Â± 0.77 % - MCC: 96.33 % Â± 1.55 %\n",
      "AUC: 99.75 % Â± 0.25 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test show load metrics wrapper func\n",
    "load_show_metrics(\"abc_k10_r1_v1.pkl\")\n",
    "load_show_metrics(\"abc_k5_r5_v1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN: 92.49 % Â± 2.82 % - FN: 3.91 % Â± 1.83 %\n",
      "FP: 7.51 % Â± 2.82 % - TP: 96.09 % Â± 1.83 %\n",
      "Precision: 92.84 % Â± 2.43 % - F1: 94.40 % Â± 1.23 % - MCC: 88.70 % Â± 2.54 %\n",
      "AUC: 98.48 % Â± 0.57 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f4070674ad0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\"\"\"Show metrics\"\"\"\n",
    "\n",
    "print(\"TN: %.02f %% Â± %.02f %% - FN: %.02f %% Â± %.02f %%\" % (np.mean(tnList),\n",
    "                                                                np.std(tnList),\n",
    "                                                                np.mean(fnList),\n",
    "                                                                np.std(fnList)))\n",
    "print(\"FP: %.02f %% Â± %.02f %% - TP: %.02f %% Â± %.02f %%\" % (np.mean(fpList),\n",
    "                                                                np.std(fpList),\n",
    "                                                                np.mean(tpList),\n",
    "                                                                np.std(tpList)))\n",
    "\n",
    "print(\n",
    "    \"Precision: %.02f %% Â± %.02f %% - F1: %.02f %% Â± %.02f %% - MCC: %.02f %% Â± %.02f %%\" % (np.mean(precisionList),\n",
    "                                                                                                np.std(precisionList),\n",
    "                                                                                                np.mean(f1List),\n",
    "                                                                                                np.std(f1List),\n",
    "                                                                                                np.mean(mccList),\n",
    "                                                                                                np.std(mccList)))\n",
    "\n",
    "print(\"AUC: %.02f %% Â± %.02f %%\" % (auc_meanpercent, auc_stdpercent))\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "            label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "            lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                    label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "xlim = [-0.05, 1.05]\n",
    "ylim = [-0.05, 1.05]\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Final function\n",
    "\n",
    "This is the main dish, its the ultra main function that wraps everything. It takes the file, what kind of classifier you want (right now it only supports adaboost), outputfile name, and some cv settings. Run the \"def train_ml_from_file(...)\" cell, and go to the child functions and run their definition cells as well, and run the children functions of those children functions and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ml_from_file(source, clf_name, save_file_name, folds=10, repeats=1):\n",
    "    X_final, y_final = data_preprocessing(source)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=folds, n_repeats=repeats, random_state=1)\n",
    "    train_cv_save_results(clf_name, cv, X_final, y_final, save_file_name)\n",
    "    load_show_metrics(save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing data...\n",
      "Non-numerical processing\n",
      "Balancing...\n",
      "Feature selection with VIF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeska\\AppData\\Local\\Temp\\ipykernel_3004\\2820370502.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-1' has dtype incompatible with datetime64[ns, UTC], please explicitly cast to a compatible dtype first.\n",
      "  tc_df.fillna(-1, inplace=True) #Replace all null values with -1\n",
      "c:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "c:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "c:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "c:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "c:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "c:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "c:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1781: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "c:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "c:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "c:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "c:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "c:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "c:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "c:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "c:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "c:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "c:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "c:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing done!\n",
      "\n",
      "Fold-repetition 1\n",
      "\n",
      "\n",
      "Fold-repetition 2\n",
      "\n",
      "\n",
      "Fold-repetition 3\n",
      "\n",
      "\n",
      "Fold-repetition 4\n",
      "\n",
      "\n",
      "Fold-repetition 5\n",
      "\n",
      "\n",
      "Showing metrics for file abc_k5_r1_test.pkl\n",
      "TN: 92.71 % Â± 1.01 % - FN: 4.57 % Â± 1.27 %\n",
      "FP: 7.29 % Â± 1.01 % - TP: 95.43 % Â± 1.27 %\n",
      "Precision: 92.91 % Â± 0.93 % - F1: 94.15 % Â± 0.88 % - MCC: 88.18 % Â± 1.77 %\n",
      "AUC: 98.34 % Â± 0.34 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ml_from_file(tc_v14_path, \"AdaBoostClassifier\", \"abc_k5_r1_test.pkl\", folds=5, repeats=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sanity testing using other datasets\n",
    "\n",
    "Since the result is suspiciously good, we want to check if the code is faulty or not by testing it against other datasets and compare results. The main code that is tested here is train_cv_save_results(...). The data_preprocessing is not really tested here because well we're using other datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The JIT palomba dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocessing\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n",
      "File \u001b[1;32mc:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\sklearn\\__init__.py:83\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     80\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     81\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     )\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     86\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    130\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester\n",
      "File \u001b[1;32mc:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\sklearn\\utils\\__init__.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclass_weight\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n",
      "File \u001b[1;32mc:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\sklearn\\utils\\validation.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _asarray_with_order, _is_numpy_namespace, get_namespace\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_isfinite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FiniteStatus, cy_isfinite\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _object_dtype_isnan\n",
      "File \u001b[1;32mc:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\sklearn\\utils\\_array_api.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wraps\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspecial\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_version\n",
      "File \u001b[1;32mc:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\scipy\\special\\__init__.py:775\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ufuncs\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ufuncs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m--> 775\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _basic\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_basic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_logsumexp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logsumexp, softmax, log_softmax\n",
      "File \u001b[1;32mc:\\Users\\yeska\\anaconda3\\envs\\machineLearningCourse\\lib\\site-packages\\scipy\\special\\_basic.py:16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ufuncs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (mathieu_a, mathieu_b, iv, jv, gamma,\n\u001b[0;32m     14\u001b[0m                       psi, hankel1, hankel2, yv, kv, poch, binom)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _specfun\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_comb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _comb_int\n\u001b[0;32m     19\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mai_zeros\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124massoc_laguerre\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeta\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     78\u001b[0m ]\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# mapping k to last n such that factorialk(n, k) < np.iinfo(np.int64).max\u001b[39;00m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:982\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:925\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1423\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1395\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1522\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:142\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "def calc_vif_jit(X):\n",
    "\n",
    "    # Calculating VIF\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return(vif)\n",
    "\n",
    "def feature_selection_jit(data, colX, subset):\n",
    "    \n",
    "    X = data[colX]\n",
    "    vif1 = calc_vif_jit(X)\n",
    "    a=vif1.VIF.max()\n",
    "    while a > 5:\n",
    "        maximum_a = vif1.loc[vif1['VIF'] == vif1['VIF'].max()]\n",
    "        vif1 = vif1.loc[vif1['variables'] != maximum_a.iloc[0,0]]\n",
    "        vif1 = calc_vif_jit(X[vif1.variables.tolist()])\n",
    "        a = vif1.VIF.max()\n",
    "        # print(a)\n",
    "\n",
    "    X = data[vif1.variables.tolist()]\n",
    "    \n",
    "    return X\n",
    "\n",
    "def jit_data_preprocessing(subset, oversampling):\n",
    "    # Read in data_raw and create the variable df to manipulate it\n",
    "    df = pd.read_csv(jit_data, low_memory=False)\n",
    "\n",
    "    # remove infinite values and NaN values\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    # variables assignement\n",
    "    y = df['contributing']\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    y = lb.fit_transform(y).ravel()\n",
    "    if subset == 'CK':\n",
    "        colX = [c for c in feature_selection_jit(df, [c for c in df.columns if \"CK_\" in c], subset)]\n",
    "    if subset == 'PROCESS':\n",
    "        colX = [c for c in feature_selection_jit(df, [c for c in df.columns if \"P_\" in c], subset)]\n",
    "    if subset == 'TEXT':\n",
    "        colX = [c for c in df.columns if \"T_\" in c]\n",
    "    if subset == 'PROCESS-TEXT':\n",
    "        colX = [c for c in feature_selection_jit(df, [c for c in df.columns if \"P_\" in c], subset)] + [c for c in df.columns if \"T_\" in c]\n",
    "    if subset == 'CK-TEXT':\n",
    "        colX = [c for c in feature_selection_jit(df, [c for c in df.columns if \"CK_\" in c], subset)] + [c for c in df.columns if \"T_\" in c]\n",
    "    if subset == 'CK-PROCESS':\n",
    "        df['PROCESS_fix'] = df['PROCESS_fix'].astype(int)\n",
    "        colX = [c for c in feature_selection_jit(df, [c for c in df.columns if \"PRODUCT_\" in c or \"PROCESS_\" in c], subset)]\n",
    "        \n",
    "    if subset == 'ALL':\n",
    "        colX = [c for c in feature_selection_jit(df, [c for c in df.columns if \"CK_\" in c or \"P_\" in c], subset)] + [c for c in df.columns if \"T_\" in c]\n",
    "\n",
    "    groups = np.array(df['project'])\n",
    "\n",
    "    projects = np.unique(groups)\n",
    "\n",
    "    projects.sort()\n",
    "    j = 1\n",
    "    input_list = []\n",
    "    target_list = []\n",
    "    group_list = []\n",
    "    for i in projects:\n",
    "        a = df[df.project.isin([i])]\n",
    "        a = a.sort_index(axis=0, inplace=False)\n",
    "        a_scaled = a[colX]\n",
    "        y = a['contributing']\n",
    "        lb = preprocessing.LabelBinarizer()\n",
    "        y = lb.fit_transform(y).ravel()\n",
    "\n",
    "\n",
    "        if oversampling == True:\n",
    "            if Counter(y)[1] > 1:\n",
    "                sm = SMOTE(random_state=0, n_jobs=-1, k_neighbors=1)\n",
    "                a_scaled, y = sm.fit_resample(a_scaled, y)\n",
    "\n",
    "\n",
    "        group_list.append([i]*len(y))\n",
    "        target_list.append(y)\n",
    "        input_list.append(a_scaled)\n",
    "        j += 1\n",
    "\n",
    "    X = np.concatenate(input_list)\n",
    "    y = np.concatenate(target_list)\n",
    "    groups = np.concatenate(group_list)\n",
    "    return X, y, groups, colX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jit = pd.read_csv(jit_data, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JIT total length 8991\n",
      "JIT vuln contributing count 90\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_jit.head\n",
    "print(\"JIT total length\", len(df_jit))\n",
    "print(\"JIT vuln contributing count\", len(df_jit[df_jit[\"contributing\"] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/imblearn/over_sampling/_smote/base.py:345: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/imblearn/over_sampling/_smote/base.py:345: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/imblearn/over_sampling/_smote/base.py:345: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/imblearn/over_sampling/_smote/base.py:345: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/imblearn/over_sampling/_smote/base.py:345: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/imblearn/over_sampling/_smote/base.py:345: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/imblearn/over_sampling/_smote/base.py:345: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17606, 36)\n",
      "(17606,)\n",
      "(17606,)\n",
      "Using: ['PRODUCT_mean_sloc', 'PRODUCT_mean_dit', 'PRODUCT_mean_noc', 'PRODUCT_mean_sloc.1', 'PRODUCT_mean_wmc.1', 'PRODUCT_mean_cbo.1', 'PRODUCT_mean_rfc.1', 'PRODUCT_mean_dit.1', 'PRODUCT_MEANmean_noc', 'PRODUCT_mean_loc.2', 'PRODUCT_mean_sloc.2', 'PRODUCT_mean_wmc.2', 'PRODUCT_mean_cbo.2', 'PRODUCT_mean_rfc.2', 'PRODUCT_mean_dit.2', 'PRODUCT_MEANmean_noc.1', 'PRODUCT_mean_lcom1', 'PRODUCT_mean_lcom2', 'PROCESS_days_after_creation', 'PROCESS_past_contributions', 'PROCESS_ratio_past_contributions', 'PROCESS_past_contributions_30_days', 'PROCESS_fix', 'PROCESS_touched_files', 'PROCESS_entropy', 'PROCESS_past_authors', 'PROCESS_sum_added_lines', 'PROCESS_sum_deleted_lines', 'PROCESS_sum_added_methods', 'PROCESS_sum_deleted_methods', 'PROCESS_sum_changed_methods', 'PROCESS_sum_added_calls', 'PROCESS_sum_added_assignments', 'PROCESS_sum_removed_assignments', 'PROCESS_sum_hunks', 'PROCESS_mean_previous_changes']\n"
     ]
    }
   ],
   "source": [
    "X_jit, y_jit, groups_jit, colX_jit = jit_data_preprocessing('CK-PROCESS', True)\n",
    "print(X_jit.shape)\n",
    "print(y_jit.shape)\n",
    "print(groups_jit.shape)\n",
    "print('Using: %s' %colX_jit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.uncentered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17606, 36)\n",
      "(17606,)\n",
      "(17606,)\n",
      "Using: ['PRODUCT_mean_sloc', 'PRODUCT_mean_dit', 'PRODUCT_mean_noc', 'PRODUCT_mean_sloc.1', 'PRODUCT_mean_wmc.1', 'PRODUCT_mean_cbo.1', 'PRODUCT_mean_rfc.1', 'PRODUCT_mean_dit.1', 'PRODUCT_MEANmean_noc', 'PRODUCT_mean_loc.2', 'PRODUCT_mean_sloc.2', 'PRODUCT_mean_wmc.2', 'PRODUCT_mean_cbo.2', 'PRODUCT_mean_rfc.2', 'PRODUCT_mean_dit.2', 'PRODUCT_MEANmean_noc.1', 'PRODUCT_mean_lcom1', 'PRODUCT_mean_lcom2', 'PROCESS_days_after_creation', 'PROCESS_past_contributions', 'PROCESS_ratio_past_contributions', 'PROCESS_past_contributions_30_days', 'PROCESS_fix', 'PROCESS_touched_files', 'PROCESS_entropy', 'PROCESS_past_authors', 'PROCESS_sum_added_lines', 'PROCESS_sum_deleted_lines', 'PROCESS_sum_added_methods', 'PROCESS_sum_deleted_methods', 'PROCESS_sum_changed_methods', 'PROCESS_sum_added_calls', 'PROCESS_sum_added_assignments', 'PROCESS_sum_removed_assignments', 'PROCESS_sum_hunks', 'PROCESS_mean_previous_changes']\n"
     ]
    }
   ],
   "source": [
    "X_jit_osf, y_jit_osf, groups_jit_osf, colX_jit_osf = jit_data_preprocessing('CK-PROCESS', False) #osf means oversampling false\n",
    "print(X_jit.shape)\n",
    "print(y_jit.shape)\n",
    "print(groups_jit.shape)\n",
    "print('Using: %s' %colX_jit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 8901, 1: 90}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def count_label_occurrences(labels):\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    label_counts = dict(zip(unique_labels, counts))\n",
    "    return label_counts\n",
    "\n",
    "count_label_occurrences(y_jit_osf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-repetition 1\n",
      "\n",
      "\n",
      "Fold-repetition 2\n",
      "\n",
      "\n",
      "Fold-repetition 3\n",
      "\n",
      "\n",
      "Fold-repetition 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Fold-repetition 5\n",
      "\n",
      "\n",
      "Fold-repetition 6\n",
      "\n",
      "\n",
      "Fold-repetition 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Fold-repetition 8\n",
      "\n",
      "\n",
      "Fold-repetition 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Fold-repetition 10\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deck/anaconda3/envs/MTML/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cv_jit = RepeatedStratifiedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "train_cv_save_results(\"AdaBoostClassifier\", cv_jit, X_jit_osf, y_jit_osf, \"jit_process_product_k10_r1_oversamp_false.pkl\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing metrics for file jit_process_product_k10_r1_oversamp_true.pkl\n",
      "TN: 94.41 % Â± 0.47 % - FN: 1.10 % Â± 0.28 %\n",
      "FP: 5.59 % Â± 0.47 % - TP: 98.90 % Â± 0.28 %\n",
      "Precision: 94.53 % Â± 0.42 % - F1: 96.67 % Â± 0.20 % - MCC: 93.35 % Â± 0.41 %\n",
      "AUC: 99.40 % Â± 0.14 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_show_metrics(\"jit_process_product_k10_r1_oversamp_true.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing metrics for file jit_process_product_k10_r1_oversamp_false.pkl\n",
      "TN: 99.96 % Â± 0.07 % - FN: 94.44 % Â± 5.56 %\n",
      "FP: 0.04 % Â± 0.07 % - TP: 5.56 % Â± 5.56 %\n",
      "Precision: 40.00 % Â± 43.59 % - F1: 9.64 % Â± 9.66 % - MCC: 14.56 % Â± 15.05 %\n",
      "AUC: 78.85 % Â± 8.19 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_show_metrics(\"jit_process_product_k10_r1_oversamp_false.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_ratio = 1 \n",
    "rus = RandomUnderSampler(sampling_strategy=desired_ratio, random_state=42)\n",
    "X_jit_osf_bal, y_jit_osf_bal = rus.fit_resample(X_jit_osf, y_jit_osf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 36) (180,)\n"
     ]
    }
   ],
   "source": [
    "print(X_jit_osf_bal.shape, y_jit_osf_bal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-repetition 1\n",
      "\n",
      "\n",
      "Fold-repetition 2\n",
      "\n",
      "\n",
      "Fold-repetition 3\n",
      "\n",
      "\n",
      "Fold-repetition 4\n",
      "\n",
      "\n",
      "Fold-repetition 5\n",
      "\n",
      "\n",
      "Fold-repetition 6\n",
      "\n",
      "\n",
      "Fold-repetition 7\n",
      "\n",
      "\n",
      "Fold-repetition 8\n",
      "\n",
      "\n",
      "Fold-repetition 9\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_jit = RepeatedStratifiedKFold(n_splits=9, n_repeats=1, random_state=1)\n",
    "train_cv_save_results(\"AdaBoostClassifier\", cv_jit, X_jit_osf_bal, y_jit_osf_bal, \"jit_process_product_k10_r1_oversamp_false_balanced.pkl\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing metrics for file jit_process_product_k10_r1_oversamp_false_balanced.pkl\n",
      "TN: 70.00 % Â± 20.00 % - FN: 28.89 % Â± 9.94 %\n",
      "FP: 30.00 % Â± 20.00 % - TP: 71.11 % Â± 9.94 %\n",
      "Precision: 72.48 % Â± 14.93 % - F1: 71.18 % Â± 10.74 % - MCC: 41.70 % Â± 25.60 %\n",
      "AUC: 77.33 % Â± 11.60 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_show_metrics(\"jit_process_product_k10_r1_oversamp_false_balanced.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just extra things because I'm too lazy to make a new file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concretely get all applications name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bookstack', 'UVDesk', 'Concrete', 'OwnCloud', 'Espocrm', 'Filegator', 'Flarum', 'Friendica', 'Hestia', 'Vesta', 'HumHub', 'InvoiceNinja', 'Kanboard', 'Kimai', 'Krayin', 'Microweber', 'Moodle', 'MyBB', 'NextCloud', 'Opencart', 'pfSense', 'phpBB', 'Pimcore', 'Piwigo', 'Shopware', 'PrivateBin', 'Sulu', 'Sylius', 'Tuleap', 'Vanilla']\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# Read the JSON file into a pandas DataFrame\n",
    "df_subset_15 = pd.read_csv(r\"C:\\Users\\yeska\\OneDrive - KU Leuven\\Documents\\master\\joris-thesis\\thesis\\data\\subsets\\15_subsets_with_nulls.csv\")\n",
    "\n",
    "# Extract the unique 'appname' values from the DataFrame\n",
    "unique_appnames = df_subset_15['appname'].unique()\n",
    "\n",
    "# Convert the unique 'appname' values into a list\n",
    "unique_appname_list = unique_appnames.tolist()\n",
    "\n",
    "# Convert the NumPy array to a DataFrame\n",
    "unique_appnames_df = pd.DataFrame(unique_appnames, columns=['appname'])\n",
    "\n",
    "# Print the list of unique appnames\n",
    "print(unique_appname_list)\n",
    "print(len(unique_appname_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gh_links = pd.read_json(r\"C:\\Users\\yeska\\OneDrive - KU Leuven\\Documents\\master\\thesis\\dataset\\application_selection\\phpAppsWithGithubLinks.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "df_gh_links.head()\n",
    "merged_df = pd.merge(df_gh_links, unique_appnames_df, on='appname', how='inner')\n",
    "print(len(merged_df))\n",
    "merged_df.head()\n",
    "print(len(merged_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Authentication\n",
    "github_token = ''#use your own personal token\n",
    "headers = {'Authorization': f'token {github_token}'}\n",
    "\n",
    "# Read the DataFrame containing github_href column\n",
    "df = merged_df\n",
    "\n",
    "# Function to fetch repository information\n",
    "def fetch_repo_info(github_href):\n",
    "    # Extract username and repository name from the GitHub URL\n",
    "    username, repo_name = github_href.split('/')[-2:]\n",
    "\n",
    "    # API endpoints\n",
    "    repo_url = f'https://api.github.com/repos/{username}/{repo_name}'\n",
    "    commits_url = f'https://api.github.com/repos/{username}/{repo_name}/commits'\n",
    "\n",
    "    # Fetch repository information\n",
    "    repo_response = requests.get(repo_url, headers=headers)\n",
    "    commits_response = requests.get(commits_url, headers=headers)\n",
    "\n",
    "    # Extract relevant information\n",
    "    if repo_response.status_code == 200 and commits_response.status_code == 200:\n",
    "        repo_info = repo_response.json()\n",
    "        commits_info = commits_response.json()\n",
    "\n",
    "        # Number of commits\n",
    "        num_commits = len(commits_info)\n",
    "\n",
    "        # Number of stars\n",
    "        num_stars = repo_info['stargazers_count']\n",
    "\n",
    "        # Description\n",
    "        description = repo_info['description']\n",
    "\n",
    "        return num_commits, num_stars, description\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "# Apply the function to fetch information for each row\n",
    "df['num_commits'], df['num_stars'], df['description'] = zip(*df['github_href'].apply(fetch_repo_info))\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv('app_list_v2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Read the DataFrame containing github_href column\n",
    "# df = pd.read_csv('app_list.csv')\n",
    "\n",
    "# Function to scrape GitHub webpage and extract number of commits\n",
    "def scrape_commits_count(github_href):\n",
    "    # Fetch the GitHub webpage\n",
    "    response = requests.get(github_href)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        # Find the span element containing the number of commits\n",
    "        commits_span = soup.find('span', class_='Text-sc-17v1xeu-0 UrHoN')\n",
    "        if commits_span:\n",
    "            print(\"commit_span exist\")\n",
    "            # Extract the text containing the number of commits\n",
    "            commits_text = commits_span.get_text(strip=True)\n",
    "            # Extract the number of commits from the text\n",
    "            num_commits = int(commits_text.split()[0])\n",
    "            return num_commits\n",
    "    return None\n",
    "\n",
    "# # Apply the function to fetch number of commits for each row\n",
    "# df['num_commits'] = df['github_href'].apply(scrape_commits_count)\n",
    "\n",
    "# # Save the updated DataFrame\n",
    "# df.to_csv('app_list.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(scrape_commits_count(\"https://github.com/nextcloud/server\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('app_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sha': 'a3a776d4a6d3a4d8d79c2a27a0e89dd929bd8b14', 'node_id': 'C_kwDOAnqaWdoAKGEzYTc3NmQ0YTZkM2E0ZDhkNzljMmEyN2EwZTg5ZGQ5MjliZDhiMTQ', 'commit': {'author': {'name': 'Dan Brown', 'email': 'ssddanbrown@googlemail.com', 'date': '2024-05-11T14:47:38Z'}, 'committer': {'name': 'Dan Brown', 'email': 'ssddanbrown@googlemail.com', 'date': '2024-05-11T14:47:38Z'}, 'message': 'Updated translator & dependency attribution before release v24.05', 'tree': {'sha': 'abc5c400b07f7ac1ee616e4afcb6b6354504feeb', 'url': 'https://api.github.com/repos/BookStackApp/BookStack/git/trees/abc5c400b07f7ac1ee616e4afcb6b6354504feeb'}, 'url': 'https://api.github.com/repos/BookStackApp/BookStack/git/commits/a3a776d4a6d3a4d8d79c2a27a0e89dd929bd8b14', 'comment_count': 0, 'verification': {'verified': True, 'reason': 'valid', 'signature': '-----BEGIN PGP SIGNATURE-----\\n\\niQIzBAABCAAdFiEERTNCzbSn5tPdcrTgRtn5Q8JKLvkFAmY/hQsACgkQRtn5Q8JK\\nLvlV3xAAktfYH1uQ7w1cNUKW1OOYQI9ZfOwPlknoOouj2GHYNH+hRE6+dw7Z0xjz\\n8nbQGTVAq0Yem6Pn/QXXvlddZq/TfNTzOYI6lNpBZbBVLnHctFs5P06djFRTf/ws\\nCCVF+iAj/89zgSnQfX+5IVJI38Zsr//ob0YgJB5prjpBW4O0K8dU36zDKzeFlAkQ\\nLf9PB/IhICgBsPnWRGdz+tJe4OeELFK/bA51sXECEV7mKL5sOJlax0iU5Ae/6i8M\\n2uiO7F0e/nvlJq5jKXW5fhSx7q+TjzFulR120o5RAR1xmnACflgS4g+hT3FPymkn\\nYIfI+iBmQb06Uq3IliMeOETI8DwNwNDQtogLZcgtDsA3/lRddEnIdeF+OPClA516\\nkd/G0Hy6HUg7eWAW3m+P1u5nW6fmhqfkbbNxQaW42L/yL5ATq8gRo+bM4RhJYgxO\\nQppuK15gdacbq+9wceS90zpJgOLmQfpqFYR8xAX51oqfOdECf/mLPTbhOa7XWtk1\\n4MKS0pKYualvEzQs3g12uSeDIQBNYaqu/ndpgV0AUYHha6bbwVizpVlSzXuQ/wnM\\nOlNdT3pv2dMrdEvzLo2+DA4uhJcHq42gciNSFPM0NSuEp0bmfVdZSnWpu3pGOMqe\\no/k+senULruyPc6780XqAyihMNw6M2qAXwYwJa+KflMDIOfz2NU=\\n=ZnFM\\n-----END PGP SIGNATURE-----', 'payload': 'tree abc5c400b07f7ac1ee616e4afcb6b6354504feeb\\nparent 2b9b0f91cbd053ecc248652db2d86ef42fd86817\\nauthor Dan Brown <ssddanbrown@googlemail.com> 1715438858 +0100\\ncommitter Dan Brown <ssddanbrown@googlemail.com> 1715438858 +0100\\n\\nUpdated translator & dependency attribution before release v24.05\\n'}}, 'url': 'https://api.github.com/repos/BookStackApp/BookStack/commits/a3a776d4a6d3a4d8d79c2a27a0e89dd929bd8b14', 'html_url': 'https://github.com/BookStackApp/BookStack/commit/a3a776d4a6d3a4d8d79c2a27a0e89dd929bd8b14', 'comments_url': 'https://api.github.com/repos/BookStackApp/BookStack/commits/a3a776d4a6d3a4d8d79c2a27a0e89dd929bd8b14/comments', 'author': {'login': 'ssddanbrown', 'id': 8343178, 'node_id': 'MDQ6VXNlcjgzNDMxNzg=', 'avatar_url': 'https://avatars.githubusercontent.com/u/8343178?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/ssddanbrown', 'html_url': 'https://github.com/ssddanbrown', 'followers_url': 'https://api.github.com/users/ssddanbrown/followers', 'following_url': 'https://api.github.com/users/ssddanbrown/following{/other_user}', 'gists_url': 'https://api.github.com/users/ssddanbrown/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/ssddanbrown/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/ssddanbrown/subscriptions', 'organizations_url': 'https://api.github.com/users/ssddanbrown/orgs', 'repos_url': 'https://api.github.com/users/ssddanbrown/repos', 'events_url': 'https://api.github.com/users/ssddanbrown/events{/privacy}', 'received_events_url': 'https://api.github.com/users/ssddanbrown/received_events', 'type': 'User', 'site_admin': False}, 'committer': {'login': 'ssddanbrown', 'id': 8343178, 'node_id': 'MDQ6VXNlcjgzNDMxNzg=', 'avatar_url': 'https://avatars.githubusercontent.com/u/8343178?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/ssddanbrown', 'html_url': 'https://github.com/ssddanbrown', 'followers_url': 'https://api.github.com/users/ssddanbrown/followers', 'following_url': 'https://api.github.com/users/ssddanbrown/following{/other_user}', 'gists_url': 'https://api.github.com/users/ssddanbrown/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/ssddanbrown/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/ssddanbrown/subscriptions', 'organizations_url': 'https://api.github.com/users/ssddanbrown/orgs', 'repos_url': 'https://api.github.com/users/ssddanbrown/repos', 'events_url': 'https://api.github.com/users/ssddanbrown/events{/privacy}', 'received_events_url': 'https://api.github.com/users/ssddanbrown/received_events', 'type': 'User', 'site_admin': False}, 'parents': [{'sha': '2b9b0f91cbd053ecc248652db2d86ef42fd86817', 'url': 'https://api.github.com/repos/BookStackApp/BookStack/commits/2b9b0f91cbd053ecc248652db2d86ef42fd86817', 'html_url': 'https://github.com/BookStackApp/BookStack/commit/2b9b0f91cbd053ecc248652db2d86ef42fd86817'}]}]\n"
     ]
    }
   ],
   "source": [
    "# Replace 'your_personal_access_token' with your actual GitHub personal access token\n",
    "github_token = ''#Please use your own personal token\n",
    "\n",
    "# Construct the URL with your token\n",
    "url = 'https://api.github.com/repos/BookStackApp/BookStack/commits?sha=development&per_page=1&page=1'\n",
    "headers = {'Authorization': f'token {github_token}'}\n",
    "\n",
    "# Make the request with authentication\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Extract and print the response content (commit information)\n",
    "    print(response.json())\n",
    "else:\n",
    "    # Print an error message if the request was not successful\n",
    "    print(f\"Error: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>href</th>\n",
       "      <th>appname</th>\n",
       "      <th>github_href</th>\n",
       "      <th>num_commits</th>\n",
       "      <th>num_stars</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/project/NextCloud</td>\n",
       "      <td>NextCloud</td>\n",
       "      <td>https://github.com/nextcloud/server</td>\n",
       "      <td>30</td>\n",
       "      <td>25718</td>\n",
       "      <td>File hosting service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/project/Bookstack</td>\n",
       "      <td>Bookstack</td>\n",
       "      <td>https://github.com/BookStackApp/BookStack</td>\n",
       "      <td>30</td>\n",
       "      <td>13924</td>\n",
       "      <td>Self hosted platform to create documentation/wiki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/project/OwnCloud</td>\n",
       "      <td>OwnCloud</td>\n",
       "      <td>https://github.com/owncloud/core</td>\n",
       "      <td>30</td>\n",
       "      <td>8273</td>\n",
       "      <td>Cloud Data storage solution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/project/Kanboard</td>\n",
       "      <td>Kanboard</td>\n",
       "      <td>https://github.com/kanboard/kanboard</td>\n",
       "      <td>30</td>\n",
       "      <td>8161</td>\n",
       "      <td>Project management software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/project/Sylius</td>\n",
       "      <td>Sylius</td>\n",
       "      <td>https://github.com/Sylius/Sylius</td>\n",
       "      <td>30</td>\n",
       "      <td>7691</td>\n",
       "      <td>Open Source eCommerce Framework on Symfony</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 href    appname                                github_href  \\\n",
       "0  /project/NextCloud  NextCloud        https://github.com/nextcloud/server   \n",
       "1  /project/Bookstack  Bookstack  https://github.com/BookStackApp/BookStack   \n",
       "2   /project/OwnCloud   OwnCloud           https://github.com/owncloud/core   \n",
       "3   /project/Kanboard   Kanboard       https://github.com/kanboard/kanboard   \n",
       "4     /project/Sylius     Sylius           https://github.com/Sylius/Sylius   \n",
       "\n",
       "   num_commits  num_stars                                        description  \n",
       "0           30      25718                               File hosting service  \n",
       "1           30      13924  Self hosted platform to create documentation/wiki  \n",
       "2           30       8273                        Cloud Data storage solution  \n",
       "3           30       8161                        Project management software  \n",
       "4           30       7691         Open Source eCommerce Framework on Symfony  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applist = pd.read_csv(\"app_list_v2.csv\")\n",
    "df_applist.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to format the number of stars\n",
    "def format_stars(num_stars):\n",
    "    if num_stars >= 1000:\n",
    "        return f\"{num_stars / 1000:.1f}k\"\n",
    "    else:\n",
    "        return f\"{num_stars:.1f}\"\n",
    "\n",
    "# Open a text file for writing\n",
    "with open('output_table.txt', 'w') as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for _, row in df_applist.iterrows():\n",
    "        # Format the number of stars\n",
    "        stars_formatted = format_stars(row['num_stars'])\n",
    "        \n",
    "        # Replace '&' with '\\&' in application name and description\n",
    "        appname = row['appname'].replace('&', r'\\&')\n",
    "        description = row['description'].replace('&', r'\\&')\n",
    "        username, repo_name = row[\"github_href\"].split('/')[-2:]\n",
    "        # Write the formatted row to the text file\n",
    "        file.write(f\"{appname} & {github_href} &{stars_formatted} & {description} \\\\\\\\ \\n\")\n",
    "        file.write(\"\\\\hline\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_stars(num_stars):\n",
    "    if num_stars >= 1000:\n",
    "        return f\"{num_stars / 1000:.1f}k\"\n",
    "    else:\n",
    "        return f\"{num_stars:.1f}\"\n",
    "\n",
    "# Open a text file for writing\n",
    "with open('output_table_v2.txt', 'w') as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for _, row in df_applist.iterrows():\n",
    "        # Format the number of stars\n",
    "        stars_formatted = format_stars(row['num_stars'])\n",
    "        \n",
    "        # Replace '&' with '\\&' in application name and description\n",
    "        appname = row['appname'].replace('&', r'\\&')\n",
    "        description = row['description'].replace('&', r'\\&')\n",
    "        github_link = row['github_href'].replace('https://', '')\n",
    "        # Write the formatted row to the text file\n",
    "        file.write(f\"{appname} & {github_link} &{stars_formatted} & {description} \\\\\\\\ \\n\")\n",
    "        file.write(\"\\\\hline\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MTML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
